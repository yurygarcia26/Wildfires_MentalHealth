{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>\n","\n","# **FILTER DATA**\n","\n","</center>\n","\n","We have collected data consisting of tweets that include words related to either wildfire, mental health, or symptoms. Our objective is to specifically filter out the tweets that are related solely to wildfire.\n","\n","\n"],"metadata":{"id":"V-gG0dbgFlEe"}},{"cell_type":"code","source":["import os\n","import glob\n","import pandas as pd\n","import re\n","import csv\n","import re\n","import string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import numpy as np"],"metadata":{"id":"jkBFAjVeVEpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BJ7L2W4VAjy"},"outputs":[],"source":["#Mount your Google Drive to Colab\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Chose the wildifire to analyze"],"metadata":{"id":"bkD7WRn8E2N_"}},{"cell_type":"code","source":["# Define the data columns types\n","dtypes = {\n","    \"tweet_id\": \"object\",\n","    \"tweet_text\":\"object\",\n","    \"tweet_possibly_sensitive\": \"bool\",\n","    \"tweet_text\": \"object\",\n","    \"tweet_source\": \"object\",\n","    \"tweet_lang\": \"object\",\n","    \"tweet_retweet_count\": \"object\",\n","    \"tweet_reply_count\":\"object\",\n","    \"tweet_like_count\": \"object\",\n","    \"tweet_quote_count\": \"object\",\n","    \"tweet_impression_count\": \"object\",\n","    \"user_id\":\"object\",\n","    \"user_username\": \"object\",\n","    \"user_verified\":\"object\",\n","    \"user_protected\":\"object\",\n","    \"user_description\":\"object\",\n","    \"user_profile_image_url\":\"object\",\n","    \"user_location\":\"object\",\n","    \"user_followers_count\":\"object\",\n","    \"user_friends_count\":\"object\",\n","    \"user_tweet_count\":\"object\",\n","    \"place_id\":\"object\",\n","    \"place_name\": \"object\",\n","    \"place_full_name\":\"object\",\n","    \"place_country\":\"object\",\n","    \"place_country_code\":\"object\",\n","    \"place_type\":\"object\"\n","}"],"metadata":{"id":"VuL70ejNujxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#name for the final file\n","file_name     = '1.TubbsFire_version1.csv'"],"metadata":{"id":"WxD5LFkeEPjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/Mental_Health_Wildfire/Twitter_Data/Tubbs_Codes/Data/'"],"metadata":{"id":"wBVbtpeXEP3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the CSV file into a Pandas DataFrame\n","df = pd.read_csv(os.path.join(file_path, file_name),dtype=dtypes)\n","print(df.shape)\n","df.head(5)"],"metadata":{"id":"JQtjnThOZ0J8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tubbs Fire"],"metadata":{"id":"KHGNHnBPwZRR"}},{"cell_type":"code","source":["#Define the words related to Tubbs\n","search_words = ['tubbsfire|wildfire|smoke|napafire|santarosafire|airquality|smokeintheair|smokeyair|fire|californiafires|napa|fires|sonomafire|smog|sonomastrong|airquality|smokeintheair|smokeyair|fire|californiafires|fires|smog|firestorm|northbayfires|calfire|norcalfires|bushfire|forestfire|grassfire|vegetation fire|burning|firestorm|wildfire|smoke']\n","\n","df['tweet_created_at'] = pd.to_datetime(df['tweet_created_at'])\n","\n","# Filter the data based on the date range Mendocino\n","df1 = df[(df['tweet_created_at'] >= '2017-10-08') & (df['tweet_created_at'] <= '2017-11-01')]\n","df1.shape\n"],"metadata":{"id":"iyNWE6U9QzsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save File"],"metadata":{"id":"v9YMvrqqaH5g"}},{"cell_type":"code","source":["output_file1 = \"2.TubbsFire_wildfire_words.csv\"\n","\n","##save data with wildfire words\n","filtered_df = df1[df1['clean_text'].str.contains('|'.join(search_words))]\n","\n","#remove dupplicated twitts\n","df_concatenated = filtered_df.drop_duplicates(subset=['tweet_id'], keep='first')\n","\n","df_concatenated.to_csv(os.path.join(file_path,output_file1), index=False)\n","print(df_concatenated.shape)\n","df_concatenated.head(5)\n","\n","df_concatenated['tweet_created_at'].max()\n","\n","#import os\n","#os.listdir(file_path)"],"metadata":{"id":"sicBwmhIR9wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##save data without wildfire words\n","\n","filtered_df = df[~df['clean_text'].str.contains('|'.join(search_words))]\n","\n","output_file1 = \"prueba.csv\"\n","filtered_df['clean_text'].to_csv(os.path.join(file_path,output_file1), index=False)"],"metadata":{"id":"jcGaAd_QjARY"},"execution_count":null,"outputs":[]}]}