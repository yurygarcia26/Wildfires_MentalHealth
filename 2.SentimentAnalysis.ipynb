{"cells":[{"cell_type":"markdown","metadata":{"id":"mIV-bpriHETM"},"source":["<center>\n","\n","# **SENTIMENT ANALYSIS**\n","\n","</center>\n","\n","We perform the analysis for the whole data without clasify those messages related to mental health.\n","\n","In this code, we use the **SentimentIntensityAnalyzer** class from the **VaderSentiment library**. The polarity_scores() method of the analyzer returns a dictionary of sentiment scores, including the compound score, which represents the overall sentiment.\n","\n","Based on the compound score, we classify the sentiment as positive, negative, or neutral using a threshold of 0.05 and -0.05.\n","\n","You'll need to install the VaderSentiment library before running this code:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pA22hrJRw1zX"},"outputs":[],"source":["pip install vaderSentiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMF3Xk0pFjFC"},"outputs":[],"source":["import pandas as pd\n","import os\n","from textblob import TextBlob\n","import re\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWRZELzUIEIg"},"outputs":[],"source":["#Mount your Google Drive to Colab\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"7ITdkcFraFqS"},"source":["Run the name of the fire you want to analyze"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWuz4cMo8rO2"},"outputs":[],"source":["#file_name = \"Tubbs_and_Thomas.csv\"\n","wildfire_name = 'Tubbs'\n","file_name     = \"2.TubbsFire_wildfire_words.csv\"\n","file_name2    = '1.Tubbs_version1.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vkah36OGZaUZ"},"outputs":[],"source":["#Set path for files\n","files_path        = '/content/drive/MyDrive/Mental_Health_Wildfire/Twitter_Data/Tubbs_Codes/Data/'\n","output_files_path = '/content/drive/MyDrive/Mental_Health_Wildfire/Twitter_Data/Tubbs_Codes/Data/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HAyC3K7JrFo"},"outputs":[],"source":["# Define the data columns types\n","dtypes = {\n","    \"tweet_id\": \"object\",\n","    \"tweet_text\":\"str\",\n","    \"tweet_possibly_sensitive\": \"bool\",\n","    \"tweet_text\": \"str\",\n","    \"tweet_source\": \"object\",\n","    \"tweet_lang\": \"str\",\n","    \"tweet_retweet_count\": \"object\",\n","    \"tweet_reply_count\":\"object\",\n","    \"tweet_like_count\": \"object\",\n","    \"tweet_quote_count\": \"object\",\n","    \"tweet_impression_count\": \"object\",\n","    \"user_id\":\"object\",\n","    \"user_username\": \"object\",\n","    \"user_verified\":\"object\",\n","    \"user_protected\":\"object\",\n","    \"user_description\":\"str\",\n","    \"user_profile_image_url\":\"float\",\n","    \"user_location\":\"float\",\n","    \"user_followers_count\":\"float\",\n","    \"user_friends_count\":\"float\",\n","    \"user_tweet_count\":\"float\",\n","    \"place_id\":\"object\",\n","    \"place_name\": \"object\",\n","    \"place_full_name\":\"object\",\n","    \"place_country\":\"object\",\n","    \"place_country_code\":\"object\",\n","    \"place_type\":\"object\",\n","    \"clean_text\":\"str\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fIQQQEZJOWU"},"outputs":[],"source":["# Load the CSV file into a Pandas DataFrame\n","\n","df = pd.read_csv(os.path.join(files_path, file_name),dtype=dtypes)\n","df[\"tweet_created_at\"] = pd.to_datetime(df[\"tweet_created_at\"])\n","\n","# Remove the hour, minute, and second information\n","df[\"tweet_created_at\"] = df[\"tweet_created_at\"].dt.date\n","\n","os.listdir(files_path)"]},{"cell_type":"code","source":["# Load the CSV file into a Pandas DataFrame\n","\n","df2 = pd.read_csv(os.path.join(files_path, file_name2),dtype=dtypes)\n","df2[\"tweet_created_at\"] = pd.to_datetime(df2[\"tweet_created_at\"])\n","\n","# Remove the hour, minute, and second information\n","df2[\"tweet_created_at\"] = df2[\"tweet_created_at\"].dt.date\n"],"metadata":{"id":"QAomWdnp0Jbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4cAle--vNU-6"},"outputs":[],"source":["print(df.shape)\n","print(df2.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ockeSDMB4jkF"},"outputs":[],"source":["# Assuming you have a DataFrame called df with a 'tweet_created_at' column\n","# Convert 'tweet_created_at' column to datetime format\n","df['tweet_created_at'] = pd.to_datetime(df['tweet_created_at'])\n","\n","# Filter data from October 4th to October 31st\n","start_date = pd.to_datetime('2017-10-08')\n","end_date   = pd.to_datetime('2017-10-31')\n","\n","filtered1 = df[(df['tweet_created_at'] >= start_date)   & (df['tweet_created_at'] <= end_date)]\n","filtered2 = df2[(df2['tweet_created_at'] >= start_date) & (df2['tweet_created_at'] <= end_date)]\n","\n","# Convert 'tweet_created_at' column to datetime format in filtered_df2\n","filtered2['tweet_created_at'] = pd.to_datetime(filtered2['tweet_created_at'])\n","\n","# Remove rows corresponding to October 13, 21, and 24, 2017\n","dates_to_remove = [\n","    pd.to_datetime('2017-10-13').date(),\n","    pd.to_datetime('2017-10-21').date(),\n","    pd.to_datetime('2017-10-24').date()\n","]\n","\n","filtered_df  = filtered1[~filtered1['tweet_created_at'].dt.date.isin(dates_to_remove)]\n","filtered_df2 = filtered2[~filtered2['tweet_created_at'].dt.date.isin(dates_to_remove)]\n","\n","\n","print(filtered_df.shape)\n","print(filtered_df2.shape)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7xyIlY01kLbq"},"source":["# Plot total tweets per day"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOJ7Wl06n6j4"},"outputs":[],"source":["df_grouped  = filtered_df.groupby(filtered_df['tweet_created_at']).size().reset_index(name='total_tweets')\n","df2_grouped = filtered_df2.groupby(filtered_df2['tweet_created_at']).size().reset_index(name='total_tweets')\n","#------------------------------\n","print(df_grouped.shape)\n","print(df2_grouped.shape)\n","\n","# Compute the average of total tweets\n","average_tweets = np.mean(df_grouped['total_tweets'])\n","\n","# Plot a bar chart\n","#plt.bar(df_grouped['tweet_created_at'], df_grouped['total_tweets'],  color='blue',   alpha= 1,  label='All Tweets')\n","#plt.bar(df2_grouped['tweet_created_at'], df2_grouped['total_tweets'],color='orange', alpha= 0.8,   label='Wildfire Related Tweets')\n","plt.fill_between(df2_grouped['tweet_created_at'], df2_grouped['total_tweets'], color='blue',   alpha= 0.7,   label='All Tweets')\n","plt.fill_between(df_grouped['tweet_created_at'], df_grouped['total_tweets'],   color='orange', alpha= 0.9,     label='Wildfire Related Tweets')\n","plt.ylim(0,df2_grouped['total_tweets'].max()+1000)\n","plt.xlim(start_date, end_date)\n","plt.xlabel('Date (days)')\n","plt.ylabel('Total Tweets')\n","plt.title('')\n","plt.xticks(rotation=0)\n","\n","# Set the x-axis tick labels to be formatted dates\n","plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n","\n","# Show the legend to differentiate between df_grouped and df2_grouped\n","plt.legend()\n","\n","# Eliminate the space between the axis and the figure\n","plt.tight_layout()\n","\n","##save figures\n","#figure_path = '/content/drive/MyDrive/Mental_Health_Wildfire/Twitter_Data/Tubbs_Codes/Figures/'\n","#figure_name = wildfire_name+'_Number_of_tweets_per_day'\n","\n","\n","# Save the figure as a PDF\n","#output_file = os.path.join(figure_path,figure_name)\n","#plt.savefig(output_file,format='pdf')\n","\n","total_sum = df2_grouped['total_tweets'].sum()\n","print(total_sum)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EZ7moJ40p6Ry"},"source":["#Sentiment analysis\n"]},{"cell_type":"markdown","metadata":{"id":"MpyUN9Mtuakf"},"source":["In this code, you can pass the clean text to the get_sentiment() function, which will then calculate the sentiment score using analyzer.polarity_scores(). It extracts the compound score and determines the sentiment category (positive, negative, or neutral) based on the compound score. Finally, it prints the compound score and sentiment.\n","\n","Using the clean text directly for sentiment analysis can be a valid approach, especially if the sentiment analysis model or library used performs well on unprocessed text. It simplifies the workflow by eliminating the need for tokenization and allows you to focus on the sentiment analysis itself."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leasENwRqMIw"},"outputs":[],"source":["def get_sentiment(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_scores = analyzer.polarity_scores(text)\n","\n","    # Extract the compound sentiment score\n","    compound_score = sentiment_scores['compound']\n","\n","    if compound_score > 0:\n","        sentiment = 'Positive'\n","    elif compound_score < 0:\n","        sentiment = 'Negative'\n","    else:\n","        sentiment = 'Neutral'\n","    print(compound_score)\n","    return compound_score"]},{"cell_type":"markdown","metadata":{"id":"7pMyYpahxH4m"},"source":["## Option 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jf9J0CjdQNXW"},"outputs":[],"source":["# Apply the sentiment analysis function to each row of the DataFrame\n","# Apply this if the file is not too long\n","\n","df['sentiment'] = df['clean_text'].apply(get_sentiment)\n","\n","# Save the updated DataFrame to a new CSV file\n","output_name = 'SA_Tubbs_tweets.csv'\n","df.to_csv(os.path.join(output_files_path, output_name), index=False)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}