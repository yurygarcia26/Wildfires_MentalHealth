{"cells":[{"cell_type":"markdown","metadata":{"id":"Mgmz5Ve1y5rq"},"source":["<center>\n","\n","#Collecting Twitter Data Related to </br>\n","#Tubbs Fire (Octubre 8-31 2017)\n","\n","<center>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6je4-aH93Je"},"outputs":[],"source":["import pandas as pd\n","import tweepy\n","import time\n","import datetime\n","import io\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8304,"status":"ok","timestamp":1687486852685,"user":{"displayName":"Yury Elena García Puerta","userId":"03711151210104919238"},"user_tz":420},"id":"Y3kNSIhVC_U5","outputId":"e14620ca-0987-4a3c-fad0-b25690b39716"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount your Google Drive to Colab\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"pdj3GKvEzMT4"},"source":["## 1. Authentication"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oL2Xrt2wy31h"},"outputs":[],"source":["\n","def getAuthentication(bearer_token):\n","\n","    print(f'\\nObteniendo autenticación...')\n","\n","    # Your app's bearer token can be found under the Authentication Tokens section\n","    # of the Keys and Tokens tab of your app, under the Twitter Developer Portal\n","\n","    # You can authenticate as your app with just your bearer token\n","    client = tweepy.Client(bearer_token=bearer_token,\n","                            wait_on_rate_limit=True)\n","\n","    return client\n"]},{"cell_type":"markdown","metadata":{"id":"zevPI76uziPv"},"source":["## 2. Search Historical Tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAJJN6FAzSH7"},"outputs":[],"source":["def searchHistoricalTweets(client, query, start_time, end_time, max_results, limit):\n","\n","    # The full-archive search endpoint returns the complete history of public Tweets matching a search query;\n","    # since the first Tweet was created March 26, 2006.\n","\n","    # By default, a request will return the most recent Tweets first (sorted by recency)\n","\n","    print(f'\\nBuscando tweets: {query}')\n","\n","    response_lst = []\n","\n","    for response in tweepy.Paginator(client.search_all_tweets,\n","                                    query,\n","                                    start_time=start_time,\n","                                    end_time=end_time,\n","                                    expansions='geo.place_id,author_id',\n","                                    place_fields=['full_name', 'id', 'country', 'country_code', 'geo', 'name', 'place_type'],\n","                                    tweet_fields=['author_id', 'created_at', 'lang', 'possibly_sensitive', 'public_metrics'],\n","                                    user_fields =['id', 'username', 'description', 'verified', 'public_metrics'],\n","                                    max_results=max_results,\n","                                    limit=limit):\n","\n","        # Response metadata\n","        print(f'{response.meta[\"result_count\"]} tweets encontrados...')\n","\n","        # Sleep 2 seconds\n","        time.sleep(2)\n","\n","        # Append raw response - Best practice to handle errors, etc.\n","        response_lst.append(response)\n","\n","\n","    return response_lst"]},{"cell_type":"markdown","metadata":{"id":"kiN721UxZALA"},"source":["## 3. Procesar Tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XD3oeUnZKn-"},"outputs":[],"source":["def processTweets(response_lst, ruta, filename_save):\n","\n","    print(f'\\nProcesando respuesta...')\n","\n","    result = []\n","    user_dict = {}\n","    place_dict = {}\n","\n","    # Loop though each response object:\n","    for response in response_lst:\n","\n","        # Take all of the users, and put them into a dictionary of dictionaries with the info to keep\n","        for user in response.includes.get('users', []):\n","            user_dict[user.id] = {'user_id': user.id,\n","                                  'user_username': user.username,\n","                                  'user_verified': user.verified,\n","                                  'user_protected': user.protected,\n","                                  'user_description': user.description,\n","                                  'user_profile_image_url': user.profile_image_url,\n","                                  'user_location': user.location,\n","                                  'user_followers_count': user.public_metrics['followers_count'],\n","                                  'user_friends_count': user.public_metrics['following_count'],\n","                                  'user_tweet_count': user.public_metrics['tweet_count']\n","                                }\n","        # Add other desired user information here\n","\n","\n","        #for user in response.includes['users']:\n","        #    user_dict[user.id] = {'user_id': user.id,\n","        #                            'user_username': user.username,\n","        #                            'user_verified': user.verified,\n","        #                            'user_protected': user.protected,\n","        #                            'user_description': user.description,\n","        #                            'user_profile_image_url': user.profile_image_url,\n","        #                            'user_location': user.location,\n","        #                            'user_followers_count': user.public_metrics['followers_count'],\n","        #                            'user_friends_count': user.public_metrics['following_count'],\n","        #                            'user_tweet_count': user.public_metrics['tweet_count']\n","        #                        }\n","\n","        # Take all of the places, and put them into a dictionary of dictionaries with the info to keep\n","        if 'places' in response.includes.keys():\n","            for place in response.includes['places']:\n","                place_dict[place.id] = {'place_id': place.id,\n","                                    'place_name': place.name,\n","                                    'place_full_name': place.full_name,\n","                                    'place_country': place.country,\n","                                    'place_country_code': place.country_code,\n","                                    'place_type': place.place_type\n","                                }\n","\n","        # Save the tweets info\n","        if response.data is not None:  # Check if response.data is not None\n","            for tweet in response.data:\n","                # For each tweet, find the author's information\n","                author_info = user_dict.get(tweet.author_id, {})\n","                place_info = place_dict.get(tweet.geo['place_id'], {}) if tweet.geo else {'place_id': None, 'place_name': None, 'place_full_name': None,\n","                                                                                            'place_country': None, 'place_country_code': None, 'place_type': None}\n","\n","                # Put all of the information we want to keep in a single dictionary for each tweet\n","                info = {\n","                    'tweet_id': tweet.id,\n","                    'tweet_text': tweet.text,\n","                    'tweet_created_at': tweet.created_at,\n","                    'tweet_source': tweet.source,\n","                    'tweet_lang': tweet.lang,\n","                    'tweet_possibly_sensitive': tweet.possibly_sensitive,\n","                    'tweet_retweet_count': tweet.public_metrics['retweet_count'],\n","                    'tweet_reply_count': tweet.public_metrics['reply_count'],\n","                    'tweet_like_count': tweet.public_metrics['like_count'],\n","                    'tweet_quote_count': tweet.public_metrics['quote_count'],\n","                    'tweet_impression_count': tweet.public_metrics['impression_count'],\n","                    'user_id': tweet.author_id,\n","                    'user_username': author_info.get('user_username'),\n","                    'user_verified': author_info.get('user_verified'),\n","                    'user_protected': author_info.get('user_protected'),\n","                    'user_description': author_info.get('user_description'),\n","                    'user_profile_image_url': author_info.get('user_profile_image_url'),\n","                    'user_location': author_info.get('user_location'),\n","                    'user_followers_count': author_info.get('user_followers_count'),\n","                    'user_friends_count': author_info.get('user_friends_count'),\n","                    'user_tweet_count': author_info.get('user_tweet_count'),\n","                    'place_id': place_info.get('place_id'),\n","                    'place_name': place_info.get('place_name'),\n","                    'place_full_name': place_info.get('place_full_name'),\n","                    'place_country': place_info.get('place_country'),\n","                    'place_country_code': place_info.get('place_country_code'),\n","                    'place_type': place_info.get('place_type')\n","                }\n","                result.append(info)\n","\n","    # Change the list of dictionaries into a dataframe\n","    df = pd.DataFrame(result)\n","\n","    # Tamaño del dataframe\n","    print(f'Total tweets {df.shape}')\n","\n","    # Exportarlo a csv\n","    print(f'Guardando :)')\n","    date_time = datetime.datetime.now().strftime('%d%m%y_%H%M%S%f') # Concatena al final fecha y hora\n","    final_name = f'{filename_save}_{date_time}.csv' # Concatena extensión de archivo\n","    df.to_csv(os.path.join(ruta, final_name), index=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qYUtDxtA70eH"},"source":["\n","### Tubbs Fire (Octobre 8-31 2017)\n","Period to download tweets: Septiembre 8 - Noviembre 30\n","Coordinates\t38.60895°N 122.62879°W\n","Most affected communities:\n","Santa Rosa, Napa, Sonoma, Calistoga, Petaluma\n","impacted by smoke: Sonoma, Lake, Mendocino, Solano\n","\n","The Tubbs Fire was a devastating wildfire that occurred in California in October 2017. Some of the most popular hashtags used during the Tubbs Fire on Twitter were:\n","\n","- #TubbsFire                - #NapaFire\n","- #SantaRosaFire            - #CaliforniaWildfires\n","- #SonomaStrong             - #PrayForCalifornia\n","- #WineCountryFires         - #FireStorm\n","- #NorthBayFires            - #SFBayFires\n","- #SonomaFire              - #CaliforniaWildfires:\n","- #NorCalFires              - #airquality\n","- #Smokeintheair            - #smokeyair\n","\n","\n","query = \"\"\"-RT (#TubbsFire OR wildfire OR smoke OR #NapaFire OR #SantaRosaFire OR #WineCountryFires OR #PrayForCalifornia OR #CaliforniaWildfires OR #NorCalFires OR #airquality OR #smokeintheair OR #smokeyair OR fire OR #californiafires)(Nightmares OR Anxiety OR Depression OR flashbacks OR struggle OR fatigue OR sad OR PTSD OR stress OR (Panic attack) OR Fear OR (Survivor guilt)) point_radius:[-122.62879 38.60895 40km] lang:en -is:retweet\"\"\"\n","\n","\n","query2  = \"\"\"-RT (#TubbsFire OR wildfire OR smoke OR #NapaFire OR #SantaRosaFire OR #WineCountryFires OR #PrayForCalifornia OR #CaliforniaWildfires OR #NorCalFires OR #airquality OR #smokeintheair OR #smokeyair OR fire OR #californiafires)(Nightmares OR Anxiety OR Depression OR flashbacks OR struggle OR fatigue OR sad OR PTSD OR stress OR (Panic attack) OR Fear OR (Survivor guilt))(Napa OR California OR (Santa Rosa) OR Sonoma OR Calistoga OR Petaluma OR Lake OR Mendocino, Solano) lang:en -is:retweet\"\"\"\n","\n","query3 = \"\"\"-RT (#TubbsFire OR wildfire OR smoke OR #NapaFire OR #SantaRosaFire OR #WineCountryFires OR #PrayForCalifornia OR #CaliforniaWildfires OR #NorCalFires OR #airquality OR #smokeintheair OR #smokeyair OR fire OR #californiafires)(anger, angry, disappointment, give up, worry, fear, nervous, worried, fussy, restless, unrestrained, caring, intolerance, impatience, stress, anxious, anxiety, restlessness, uneasiness, frightened, (I am afraid), apprehension, terrible, nightmarish, (Im afraid), worry, restlessness, worthless, cant sleep, insomnia, sleepy, want to sleep, (I cant concentrate), (I cant get distracted), tension, tense, cant rest, (I cant forget an unpleasant memory), (unpleasant memories dont leave me), (I cant forget unpleasant sights), (unpleasant sights dont leave me), (cant forget unpleasant things), (I remember unpleasant memories), (I remember bad memories), (I remember unpleasant views), (I remember an unpleasant sight), melancholy, (feel bad), (feeling depressed), joyless, (not funny), uninterested, (not interested in anything), boring, tired, fatigue, no energy, no appetite, (do not want to eat), overeating, unable to move, motionless, feel heaviness, (want to die), (want to disappear), (terrible dream), horror, flashback, trembling, palpitation, suffocating, excitement, inquisitiveness, (I dont want to think), (I dont want to remember), (I want to forget), (I dont want to talk), (I dont want to go), (I dont want to see), (I cant remember), (I dont remember), alienation, seclusion, loneliness, solitude, isolation, without emotion, emotional paralysis, (somehow it will happen), (dont lose heart), (dont give up)) point_radius:[-122.62879 38.60895 40km] lang:en -is:retweet\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"AYMzG3wtcemV"},"source":["# Run the code by days"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_23SM0L3R5n"},"outputs":[],"source":["bearer_token = 'TOKEN'\n","\n","# Define the start and end times (9/8/2017 - 01-01-2018)\n","start_time = '2017-09-01T00:00:00Z' # inclusive\n","end_time   = '2017-09-02T00:00:00Z' # exclusive\n","\n","client = getAuthentication(bearer_token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j57Vh3ZccdOx"},"outputs":[],"source":["#query   = \"\"\"-RT (\"I was diagnosed\" OR \"I've been diagnosed\" OR \"I have been diagnosed\" OR \"I'm diagnosed\") (depression OR \"depressive disorder\") lang:en -is:retweet\"\"\"\n","query   = \"\"\"-RT (#TubbsFire OR wildfire OR smoke OR #NapaFire OR #SantaRosaFire OR #WineCountryFires OR #PrayForCalifornia OR #CaliforniaWildfires OR #NorCalFires OR #airquality OR #smokeintheair OR #smokeyair OR fire OR Nightmares OR Anxiety OR Depressio OR Panic attacks OR Survivor guilt OR #PTSD OR PTSD OR #stress OR stress OR #struggle OR struggle OR sad OR #sad OR #flashbacks OR #californiafires OR #evacuation OR #disaster OR #fatigue OR #smokeinhalation OR #respiratoryproblems OR  #asthma OR  #COPD OR  #lunghealth OR #burningeyes OR #sorethroat OR #headaches OR #fatigue OR #stress OR  coughing OR wheezing OR breath OR asthma OR  bronchitis OR  (Eye irritation) OR (nose irritation) OR congestion OR irritation OR Headaches OR fatigue OR itching OR irritation OR redness OR inflammation OR dryness OR flakiness OR discomfort OR rashes OR hives OR \"I was diagnosed\" OR \"I've been diagnosed\" OR \"I have been diagnosed\" OR \"I'm diagnosed\") point_radius:[-122.62879 38.60895 40km] lang:en -is:retweet\"\"\"\n","\n","#query = \"\"\"-RT (#TubbsFire OR wildfire OR smoke OR #NapaFire OR #SantaRosaFire OR #WineCountryFires OR #PrayForCalifornia OR #CaliforniaWildfires OR #NorCalFires OR #airquality OR #smokeintheair OR #smokeyair OR fire) (Nightmares OR flashbacks OR struggle OR fatigue OR sad OR PTSD OR stress OR Anxiety OR Depression OR (Panic attack) OR Fear OR Fear OR (Survivor guilt)) point_radius:[-123.103367 39.243283 40km] lang:en -is:retweet\"\"\"\n","\n","#without geolocation\n","#query = \"\"\"-RT (#MentalHealth OR Nightmares OR flashbacks OR struggle OR fatigue OR sad OR PTSD OR stress OR Anxiety OR Depression OR Panic attack OR Fear OR depressed OR anxious OR angry OR disappointment OR \"give up\" OR worry OR worried OR nervous OR fussy OR restless OR intolerance OR impatience OR restlessness OR #stress OR #struggle OR frightened OR #sad OR apprehension OR terrible OR \"can't sleep\" OR insomnia OR \"want to sleep\" OR \"I can't concentrate\" OR tension OR tense OR \"can't rest\" OR \"can't forget\" OR \"bad memories\" OR melancholy OR \"feel sad\" OR joyless OR \"not funny\" OR uninterested OR \"not interested\" OR boring OR tired OR fatigue OR \"no energy\" OR \"no appetite\" OR \"do not want\" OR overeating OR \"unable to move\" OR motionless OR \"feel heaviness\" OR \"want to die\" OR \"want to disappear\" OR \"terrible dream\" OR horror OR suffocating OR \"I can't remember\" OR \"I don't remember\" OR alienation OR loneliness OR solitude OR isolation) point_radius:[-122.62879 38.60895 40km] lang:en -is:retweet\"\"\"\n","\n","max_results = 500\n","limit = 20\n","ruta  = '/content/drive/MyDrive/Mental_Health_Wildfire/Twitter_Data/1.Collecting_data/ResultsTubbsFire'\n","\n","# Define the time interval for the loop\n","interval = 3*60  # in seconds\n","\n","#Last day of the month we want to collect\n","\n","limit_perio = '2018-01-01T00:00:00Z'\n","while start_time < limit_perio:\n","\n","    # Search for tweets\n","    response_lst = searchHistoricalTweets(client, query, start_time, end_time, max_results, limit)\n","\n","    # Process the tweets if there are any\n","    if response_lst[0].meta['result_count']>0:\n","      processTweets(response_lst,ruta,'resultados')\n","\n","    # Update the start and end times for the next iteration\n","    start_time = end_time\n","    end_time   = (datetime.datetime.fromisoformat(end_time[:-1]) + datetime.timedelta(days=1)).isoformat() + 'Z'\n","\n","    # Wait for the specified interval before the next search\n","    time.sleep(interval)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}